{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa4e01e7",
   "metadata": {},
   "source": [
    "# Main Notebook for Automated Multisubject Processing\n",
    "\n",
    "This is the main overall script for performing technical validation and basic classification.\n",
    "First the meta data should be loaded and altered based on which subjects and sessions are being used. Also included is the scipt used for converting the EEG data files into BIDS format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2419ab0",
   "metadata": {},
   "source": [
    "### For Technical Validation:\n",
    "\n",
    "*Multisensory_EEG_DataSet Save:* This script can be used for saving processed ICA data (with the prior preprocessing steps applied), into .fif files for each subject.\n",
    "\n",
    "\n",
    "*epoch-save:* This script loads the .fif files and converts them into epochs, and then saves them into folders based on the conditions (multiple subjects in each folder)\n",
    "\n",
    "*Time Frequency Representation:*  This script computes the intertrial coherence, and also the PSD averaged across trials and subjects for each condition\n",
    "\n",
    "*ERP:* This script is used to compute the average ERP across subjects for particular tasks and modalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb2045",
   "metadata": {},
   "source": [
    "### For Classification:\n",
    "\n",
    "Currently implemented is logistic regression. These scripts can be taken and expanded to implement more advanced classification pipelines, with different feature extraction techniques.\n",
    "\n",
    "*Basic_Task_Classification:* This script can be used for classifying between perception or imagination tasks for each subject, for each sensory modality\n",
    "\n",
    "\n",
    "*Classification_Sensory_Modalities:* This script can be used for classifying between the three sensory modalities (pictorial, orthographic or audio) for each subject, and within each task (imagination vs. perception)\n",
    "\n",
    "*Classification_Semantic:*  This script can be used for classifying between the three semantic categories (penguin, guitar or flower) for each subject, and within each task (imagination vs. perception), and within the three sensory modalities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44c3fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import papermill as pm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5717cfb6",
   "metadata": {},
   "source": [
    "### Load up the meta data\n",
    "This includes information on the subject session, cap size, bad channels and any other relevant notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899ef127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up the parameter csv\n",
    "param_data = pd.read_csv(\"X:\\\\CompSci\\\\ResearchProjects\\\\EJONeill\\\\Neuroimaging\\\\multisensoryeeg\\\\openNeuro\\\\meta_extended.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c22b4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sub</th>\n",
       "      <th>sess</th>\n",
       "      <th>cap</th>\n",
       "      <th>bad_channels</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>L</td>\n",
       "      <td>TPP9h, CCP1h</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>CCP2h</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>CP3, FCC3h, CPP3h</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>M1, CCP2h</td>\n",
       "      <td>good impedances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>FC1, C3, Cz, CP1, P3, FCz, C1, CP3, P5, FCC3h,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>L</td>\n",
       "      <td>CCP1h</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>CCP1h, POO10h</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>M1, FT9, FCC5h, CCP1h</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>M1, CCP1h, FFC3h</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  sub  sess cap                                       bad_channels  \\\n",
       "0       0    3     3   L                                      TPP9h, CCP1h    \n",
       "1       1    8     3   M                                              CCP2h   \n",
       "2       2   10     1   M                                  CP3, FCC3h, CPP3h   \n",
       "3       3   11     1   M                                          M1, CCP2h   \n",
       "4       4   12     1   L  FC1, C3, Cz, CP1, P3, FCz, C1, CP3, P5, FCC3h,...   \n",
       "5       5   12     2   L                                              CCP1h   \n",
       "6       6   13     1   L                                      CCP1h, POO10h   \n",
       "7       7   14     1   L                                                NaN   \n",
       "8       8   14     2   L                                                NaN   \n",
       "9       9   15     1   L                                                NaN   \n",
       "10     10   15     2   L                                                NaN   \n",
       "11     11   16     1   L                              M1, FT9, FCC5h, CCP1h   \n",
       "12     12   17     1   L                                   M1, CCP1h, FFC3h   \n",
       "13     13   18     1   L                                                NaN   \n",
       "14     14   19     1   L                                                NaN   \n",
       "\n",
       "              notes  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3   good impedances  \n",
       "4               NaN  \n",
       "5               NaN  \n",
       "6               NaN  \n",
       "7               NaN  \n",
       "8               NaN  \n",
       "9               NaN  \n",
       "10              NaN  \n",
       "11              NaN  \n",
       "12              NaN  \n",
       "13              NaN  \n",
       "14              NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reformat the dataframe, reset index to make iteratble\n",
    "param_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d94308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop certain participants based on index\n",
    "labels = []\n",
    "\n",
    "param_data = param_data.drop(labels=labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0d639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64b2845",
   "metadata": {},
   "source": [
    "# Code used for converting the files to BIDs format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in param_data.iterrows():\n",
    "    print(\"For subject \", str(row[\"sub\"]), \" and session \", str(row[\"sess\"]), \" converting data to bids format\")\n",
    "    pm.execute_notebook(\n",
    "    'X:\\\\CompSci\\\\ResearchProjects\\\\EJONeill\\\\Neuroimaging\\\\multisensoryeeg\\\\openNeuro\\\\code\\\\convert_bids.ipynb',\n",
    "   'bids_output.ipynb',\n",
    "    parameters=dict(ppt_num=str(row[\"sub\"]), session=str(row[\"sess\"]),\n",
    "    overwrite=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1976936",
   "metadata": {},
   "source": [
    "## Below is for saving processed ICA data\n",
    "This runs the *Multisensory_EEG_Preprocess_Save.ipynb* script on all subjects and sessions listed in the meta-extended file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a642bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run each row (assign parameters from file to dictionary)\n",
    "for index, row in param_data.iterrows():\n",
    "    print(row['bad_channels'])\n",
    "    if pd.isna(row['bad_channels']):\n",
    "        print(\"there are no bad channels\")\n",
    "        bad_chans = []\n",
    "        # should replace it with an empty list\n",
    "    else:\n",
    "        bad_chans = row['bad_channels'].split(\",\")\n",
    "        bad_chans = [s.strip() for s in bad_chans] # get rid of the extra white space that appears\n",
    "    print(bad_chans)\n",
    "    print(\"For subject \", str(row[\"sub\"]), \" and session \", str(row[\"sess\"]), \" running preprocessing\")\n",
    "    pm.execute_notebook(\n",
    "    # process bad channel into usable format\n",
    "    'X:\\\\CompSci\\\\ResearchProjects\\\\EJONeill\\\\Neuroimaging\\\\multisensoryeeg\\\\openNeuro\\\\code\\\\preprocess_automate_chans.ipynb',\n",
    "   'ica_output.ipynb',\n",
    "    parameters=dict(ppt_num=str(row[\"sub\"]), session=str(row[\"sess\"]), cap_size = str(row[\"cap\"]), bad_chans=bad_chans)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683e0d75",
   "metadata": {},
   "source": [
    "## Below is for epoching data, and saving it for each condition separately\n",
    "This uses the *epoch-save.ipynb* script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5521f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run each row (assign parameters from file to dictionary)\n",
    "\n",
    "\n",
    "for index, row in param_data.iterrows():\n",
    "    print(\"For subject \", str(row[\"sub\"]), \" and session \", str(row[\"sess\"]), \" running epoch-saving ready for trf\")\n",
    "    pm.execute_notebook(\n",
    "    'X:\\\\CompSci\\\\ResearchProjects\\\\EJONeill\\\\Neuroimaging\\\\multisensoryeeg\\\\openNeuro\\\\code\\\\epoch-save.ipynb',\n",
    "   'epoch_output.ipynb',\n",
    "    parameters=dict(ppt_num=str(row[\"sub\"]), session=str(row[\"sess\"]), cap_size = str(row[\"cap\"]),\n",
    "    overwrite=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9d31b6",
   "metadata": {},
   "source": [
    "## Computing the time frequency representation analysis\n",
    "The intertrial coherence and power spectral density plots are computed on the combination of all subjects, but for each condition separately (though ignoring the semantic categories here). Including:\n",
    "-  imagination orthographic\n",
    "-  imagination audio\n",
    "-  imagination pictorial\n",
    "-  perception orthographic\n",
    "-  perception audio\n",
    "-  perception pictorial\n",
    "\n",
    "The script used is *Time_Frequency_Representation.ipynb*. Output should be the plot images, saved with the title of the condition, and also files with the actual power and ITC numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330e6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.execute_notebook(\n",
    "   'X:\\\\CompSci\\\\ResearchProjects\\\\EJONeill\\\\Neuroimaging\\\\multisensoryeeg\\\\openNeuro\\\\code\\\\Time_Frequency_Representation.ipynb',\n",
    "   'tfr_output.ipynb',\n",
    "   parameters=dict(alpha=0.6, ratio=0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2323a4c5",
   "metadata": {},
   "source": [
    "## Average ERPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d3891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.execute_notebook(\n",
    "   'X:\\\\CompSci\\\\ResearchProjects\\\\EJONeill\\\\Neuroimaging\\\\multisensoryeeg\\\\openNeuro\\\\code\\\\ERP.ipynb',\n",
    "   'erp_output.ipynb',\n",
    "   parameters=dict(alpha=0.6, ratio=0.1)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3302cfdb",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dfa530",
   "metadata": {},
   "source": [
    "## Classification between Imagination and Perception\n",
    "Set the task choice (pictorial, orthographic or audio) below, and the number of iterations to average over for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b519743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Black is not installed, parameters wont be formatted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For subject  3  and session  3  running classification between imagination and perception for pictorial task. This is over 50 iterations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eef774df881411db26d2203dbd51194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/22 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task = 'pictorial'\n",
    "iterations = 50\n",
    "\n",
    "for index, row in param_data.iterrows():\n",
    "    print(\"For subject \", str(row[\"sub\"]), \" and session \", str(row[\"sess\"]), ' running classification between imagination and perception for ' + task \n",
    "          + ' task. This is over '+str(iterations)+' iterations')\n",
    "    pm.execute_notebook(\n",
    "    'X:\\\\CompSci\\\\ResearchProjects\\\\EJONeill\\\\Neuroimaging\\\\multisensoryeeg\\\\openNeuro\\\\code\\\\Basic_Task_Classification.ipynb',\n",
    "   'classification.ipynb',\n",
    "    parameters=dict(subject=str(row[\"sub\"]), session=str(row[\"sess\"]), task=task, iterations = iterations),\n",
    "    overwrite=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc4918a",
   "metadata": {},
   "source": [
    "## Classification between Sensory Modalities\n",
    "Classify whether the task is orthographic, audio or pictorial. Parameters to set is whether the overall task is imagination or perception, and the amount of iterations to average over. Results are stored in a .csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07ef8fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Black is not installed, parameters wont be formatted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For subject  3  and session  3  running classification between the three sensory modalities\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0dc5f04f5c540c89c918f8765839424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/15 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task = 'perception'\n",
    "iterations = 50\n",
    "\n",
    "for index, row in param_data.iterrows():\n",
    "    print(\"For subject \", str(row[\"sub\"]), \" and session \", str(row[\"sess\"]), \" running classification between the three sensory modalities\")\n",
    "    pm.execute_notebook(\n",
    "    'X:\\\\CompSci\\\\ResearchProjects\\\\EJONeill\\\\Neuroimaging\\\\multisensoryeeg\\\\openNeuro\\\\code\\\\Classification_Sensory_Modalities.ipynb',\n",
    "   'classifications.ipynb',\n",
    "    parameters=dict(subject=str(row[\"sub\"]), session=str(row[\"sess\"]), task= task, iterations = iterations,\n",
    "    overwrite=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1094a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "37a69b0d",
   "metadata": {},
   "source": [
    "### Classification between Semantic categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4828c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "modality = 'pictorial'\n",
    "task = 'perception'\n",
    "iterations = 50\n",
    "\n",
    "for index, row in param_data.iterrows():\n",
    "    print(\"For subject \", str(row[\"sub\"]), \" and session \", str(row[\"sess\"]), \" running classification between the three semantic modalities\")\n",
    "    pm.execute_notebook(\n",
    "    'X:\\\\CompSci\\\\ResearchProjects\\\\EJONeill\\\\Neuroimaging\\\\multisensoryeeg\\\\openNeuro\\\\code\\\\Classification_Semantic.ipynb',\n",
    "   'classification_pictorial.ipynb',\n",
    "    parameters=dict(subject=str(row[\"sub\"]), session=str(row[\"sess\"]), task= task, modality =modality, iterations = iterations,\n",
    "    overwrite=True) \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
